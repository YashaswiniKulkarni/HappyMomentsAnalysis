{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "454fd7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>wid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>original_hm</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>modified</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>ground_truth_category</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27673</td>\n",
       "      <td>2053</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27674</td>\n",
       "      <td>2</td>\n",
       "      <td>24h</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27675</td>\n",
       "      <td>1936</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27676</td>\n",
       "      <td>206</td>\n",
       "      <td>24h</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27677</td>\n",
       "      <td>6227</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid   wid reflection_period  \\\n",
       "0  27673  2053               24h   \n",
       "1  27674     2               24h   \n",
       "2  27675  1936               24h   \n",
       "3  27676   206               24h   \n",
       "4  27677  6227               24h   \n",
       "\n",
       "                                         original_hm  \\\n",
       "0  I went on a successful date with someone I fel...   \n",
       "1  I was happy when my son got 90% marks in his e...   \n",
       "2       I went to the gym this morning and did yoga.   \n",
       "3  We had a serious talk with some friends of our...   \n",
       "4  I went with grandchildren to butterfly display...   \n",
       "\n",
       "                                          cleaned_hm  modified  num_sentence  \\\n",
       "0  I went on a successful date with someone I fel...      True             1   \n",
       "1  I was happy when my son got 90% marks in his e...      True             1   \n",
       "2       I went to the gym this morning and did yoga.      True             1   \n",
       "3  We had a serious talk with some friends of our...      True             2   \n",
       "4  I went with grandchildren to butterfly display...      True             1   \n",
       "\n",
       "  ground_truth_category predicted_category  \n",
       "0                   NaN          affection  \n",
       "1                   NaN          affection  \n",
       "2                   NaN           exercise  \n",
       "3               bonding            bonding  \n",
       "4                   NaN          affection  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "url=\"https://raw.githubusercontent.com/megagonlabs/HappyDB/master/happydb/data/cleaned_hm.csv\"\n",
    "s=requests.get(url).content\n",
    "happyDB=pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "pd.set_option('display.max_columns', None)\n",
    "happyDB.head()\n",
    "\n",
    "#Here we are loading the dataset. The HappyDB is a publicly available dataset \n",
    "#containing text excerpts that describe moments of happiness shared by individuals. \n",
    "#It was created by collecting and anonymizing personal diary entries, social media posts, \n",
    "#and survey responses, providing insights into what makes people happy in various aspects of their lives, \n",
    "#such as relationships, activities, and experiences. Researchers and data analysts use this dataset to \n",
    "#study and understand the factors contributing to happiness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f5915",
   "metadata": {},
   "source": [
    "# Lexicon-based Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "484cbec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relationship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auntie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aunties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aunts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aunty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>act(or|ress)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>lady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>teacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>celebrity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Relationship\n",
       "0            aunt\n",
       "1          auntie\n",
       "2         aunties\n",
       "3           aunts\n",
       "4           aunty\n",
       "..            ...\n",
       "234  act(or|ress)\n",
       "235          lady\n",
       "236       teacher\n",
       "237     celebrity\n",
       "238     professor\n",
       "\n",
       "[239 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relationship_lexicon = pd.read_csv(\"C:/Users/yashu/Downloads/people-dict.csv\",header=None)\n",
    "relationship_lexicon.columns=[\"Relationship\"]\n",
    "\n",
    "#We are analyzing the happy moments dataset using LEXICON based analysis. We are \n",
    "#using the lexicon, people_dict which contains names, identifiers like \"Mom\", \"Dad\",\n",
    "#\"best friend\" and so on. Researchers and analysts can use the people dictionary to track mentions of \n",
    "#specific individuals in the text data. This can be valuable for understanding the social aspects of happiness, \n",
    "#including who is contributing to people's happiness and the nature of their relationships.\n",
    "#Combining both dictionaries, researchers can analyze happy moments in the HappyDB dataset by \n",
    "#categorizing them into topics (using the topic dictionary) and identifying the individuals \n",
    "#involved (using the people dictionary). This dual approach allows for a more nuanced \n",
    "#understanding of the factors and relationships that contribute to happiness in people's lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dac56242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Relationship\n",
      "0                    aunt\n",
      "1                  auntie\n",
      "2                 aunties\n",
      "3                   aunts\n",
      "4                   aunty\n",
      "5                  babies\n",
      "6                    baby\n",
      "7                     bae\n",
      "8             best friend\n",
      "9              bestfriend\n",
      "10            bestfriends\n",
      "11                 bestie\n",
      "12                besties\n",
      "13                     bf\n",
      "14                    bff\n",
      "15                   bffs\n",
      "16                    boy\n",
      "17              boyfriend\n",
      "18                   boys\n",
      "19                    bro\n",
      "20                brother\n",
      "21         brother-in-law\n",
      "22               brothers\n",
      "23                buddies\n",
      "24                  buddy\n",
      "25                  child\n",
      "26               children\n",
      "27           close friend\n",
      "28              co-worker\n",
      "29              colleague\n",
      "30                 cousin\n",
      "31                cousins\n",
      "32               coworker\n",
      "33                    dad\n",
      "34                  daddy\n",
      "35                   dads\n",
      "36               daughter\n",
      "37        daughter-in-law\n",
      "38              daughters\n",
      "39                  dudes\n",
      "40          elder brother\n",
      "41              elder son\n",
      "42                 eldest\n",
      "43             eldest son\n",
      "44              everybody\n",
      "45               everyone\n",
      "46           ex-boyfriend\n",
      "47          ex-girlfriend\n",
      "48             ex-husband\n",
      "49                ex-wife\n",
      "50               families\n",
      "51                 family\n",
      "52                 father\n",
      "53          father-in-law\n",
      "54                 fiance\n",
      "55                fiancee\n",
      "56                 fiancé\n",
      "57                fiancée\n",
      "58                  folks\n",
      "59                 friend\n",
      "60                friends\n",
      "61                     gf\n",
      "62                   girl\n",
      "63             girlfriend\n",
      "64                  girls\n",
      "65            good friend\n",
      "66         grand-daughter\n",
      "67           grandaughter\n",
      "68             grandchild\n",
      "69          grandchildren\n",
      "70          granddaughter\n",
      "71         granddaughters\n",
      "72            grandfather\n",
      "73           grandfathers\n",
      "74                grandma\n",
      "75               grandmas\n",
      "76            grandmother\n",
      "77           grandmothers\n",
      "78                grandpa\n",
      "79           grandparents\n",
      "80               grandson\n",
      "81              grandsons\n",
      "82               grannies\n",
      "83                 granny\n",
      "84    great-grandchildren\n",
      "85    great-granddaughter\n",
      "86      great-grandfather\n",
      "87      great-grandmother\n",
      "88         great-grandson\n",
      "89   great-great-grandson\n",
      "90                    guy\n",
      "91                   guys\n",
      "92                  hubby\n",
      "93                husband\n",
      "94                 in-law\n",
      "95                in-laws\n",
      "96                 infant\n",
      "97                infants\n",
      "98                 inlaws\n",
      "99                    kid\n",
      "100                  kids\n",
      "101                 lover\n",
      "102                  mama\n",
      "103                 mamma\n",
      "104                   man\n",
      "105                   mom\n",
      "106                 momma\n",
      "107                 mommy\n",
      "108                  moms\n",
      "109                mother\n",
      "110         mother-in-law\n",
      "111               mothers\n",
      "112                   mum\n",
      "113                 neice\n",
      "114              neighbor\n",
      "115             neighbors\n",
      "116             neighbour\n",
      "117            neighbours\n",
      "118                nephew\n",
      "119               nephews\n",
      "120               newborn\n",
      "121              newborns\n",
      "122                 niece\n",
      "123                nieces\n",
      "124         older brother\n",
      "125            oldest son\n",
      "126              only son\n",
      "127                  pals\n",
      "128                  papa\n",
      "129                 pappa\n",
      "130                parent\n",
      "131               parents\n",
      "132               partner\n",
      "133              partners\n",
      "134                people\n",
      "135                person\n",
      "136                   ppl\n",
      "137          preschoolers\n",
      "138            second son\n",
      "139                sister\n",
      "140         sister-in-law\n",
      "141               sisters\n",
      "142        sisters-in-law\n",
      "143              somebody\n",
      "144               someone\n",
      "145                   son\n",
      "146            son-in-law\n",
      "147                  sons\n",
      "148           step-father\n",
      "149           step-mother\n",
      "150          stepdaughter\n",
      "151            stepfather\n",
      "152            stepmother\n",
      "153               stepson\n",
      "154                  them\n",
      "155               toddler\n",
      "156              toddlers\n",
      "157                 uncle\n",
      "158                uncles\n",
      "159                  wife\n",
      "160                 woman\n",
      "161       younger brother\n",
      "162           younger son\n",
      "163          youngest son\n",
      "164               fathers\n",
      "165              siblings\n",
      "166                 chick\n",
      "167                chicks\n",
      "168               sibling\n",
      "169                  babe\n",
      "170           girlfriends\n",
      "171              brunette\n",
      "172                 babes\n",
      "173            boyfriends\n",
      "174                blonde\n",
      "175                   bby\n",
      "176                 cutie\n",
      "177                 blond\n",
      "178               hotties\n",
      "179               blondes\n",
      "180             brunettes\n",
      "181                blonds\n",
      "182                 women\n",
      "183                   men\n",
      "184                 peeps\n",
      "185    great-grandparents\n",
      "186               stepdad\n",
      "187             coworkers\n",
      "188            co-workers\n",
      "189             grandkids\n",
      "190                every1\n",
      "191                 some1\n",
      "192                 tenns\n",
      "193                 teens\n",
      "194                  teen\n",
      "195             teenagers\n",
      "196              teenager\n",
      "197              my crush\n",
      "198                 my ex\n",
      "199             his crush\n",
      "200             her crush\n",
      "201                his ex\n",
      "202                her ex\n",
      "203            only child\n",
      "204          twin brother\n",
      "205                ladies\n",
      "206              redheads\n",
      "207         only daughter\n",
      "208               mommies\n",
      "209                adults\n",
      "210       eldest daughter\n",
      "211        youngest child\n",
      "212     youngest daughter\n",
      "213          eldest child\n",
      "214                   sis\n",
      "215               stepmom\n",
      "216                 mummy\n",
      "217                kiddos\n",
      "218                fellas\n",
      "219                 fella\n",
      "220                 bloke\n",
      "221                   lad\n",
      "222            colleagues\n",
      "223                blokes\n",
      "224                  lads\n",
      "225                 adult\n",
      "226      childhood friend\n",
      "227              customer\n",
      "228                client\n",
      "229              stranger\n",
      "230             strangers\n",
      "231             co worker\n",
      "232       love of my life\n",
      "233         [\\w]*mate(s?)\n",
      "234          act(or|ress)\n",
      "235                  lady\n",
      "236               teacher\n",
      "237             celebrity\n",
      "238             professor\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "print(relationship_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "546102c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'someone': 784, 'son': 6274, 'his ex': 44, 'friend': 13419, 'friends': 4527, 'child': 1584, 'children': 632, 'grandchild': 72, 'grandchildren': 54, 'bro': 3147, 'brother': 1511, 'elder brother': 16, 'mom': 4282, 'moms': 29, 'teen': 123, 'neighbour': 46, 'man': 3410, 'girl': 2921, 'family': 4222, 'sister': 1756, 'sis': 2211, 'people': 1237, 'grandmother': 248, 'mother': 1901, 'husband': 2683, 'customer': 200, 'men': 7038, 'daughter': 3478, 'mama': 46, 'everyone': 454, 'kid': 1427, 'kids': 1098, 'them': 2156, 'childhood friend': 103, 'neighbor': 597, 'fiance': 394, 'fiancee': 131, 'colleague': 327, 'colleagues': 218, 'best friend': 958, 'partner': 357, 'close friend': 251, 'girlfriend': 1993, 'baby': 1189, 'women': 91, 'chick': 457, 'boy': 1697, 'boyfriend': 1265, 'daughters': 199, 'granddaughter': 148, 'granddaughters': 9, 'uncle': 419, 'parent': 1251, 'parents': 1116, 'siblings': 52, 'sibling': 77, 'dad': 936, 'professor': 92, 'ladies': 21, 'lad': 587, 'wife': 2716, 'ppl': 622, 'families': 59, 'guy': 286, 'guys': 58, 'mothers': 123, 'person': 1049, 'woman': 220, 'blond': 6, 'teenager': 25, 'father': 773, 'neice': 16, 'nephew': 466, 'lover': 115, 'cousin': 591, 'good friend': 308, 'buddies': 31, 'in-law': 185, 'mother-in-law': 41, 'stranger': 116, 'ex-wife': 8, 'my ex': 325, 'only daughter': 2, 'client': 236, 'youngest child': 39, 'fathers': 30, 'mum': 125, 'boys': 106, 'coworker': 480, 'lady': 156, 'co worker': 53, 'sons': 306, 'teacher': 271, 'coworkers': 188, 'my crush': 64, 'adult': 76, 'youngest daughter': 56, 'stepdaughter': 4, 'sister-in-law': 35, 'aunt': 249, 'grandson': 141, 'grandsons': 10, 'co-worker': 215, 'co-workers': 84, 'sisters': 125, 'mummy': 26, 'niece': 482, 'girls': 150, 'partners': 17, 'eldest': 24, 'eldest daughter': 5, 'oldest son': 63, 'gf': 100, 'neighbors': 127, 'cousins': 151, 'older brother': 27, 'infant': 24, 'teens': 4, 'youngest son': 78, 'babies': 57, 'bf': 10, 'bff': 5, 'toddler': 108, 'brothers': 117, 'daddy': 87, 'grandkids': 27, 'stepson': 8, 'somebody': 86, 'boyfriends': 16, 'grandfather': 80, 'grandfathers': 3, 'neighbours': 21, 'son-in-law': 6, 'celebrity': 13, 'nephews': 65, 'hubby': 41, 'bby': 123, 'stepmother': 4, 'nieces': 64, 'granny': 1, 'father-in-law': 16, 'aunty': 19, 'toddlers': 11, 'ex-girlfriend': 12, 'girlfriends': 43, 'her ex': 40, 'grandpa': 189, 'papa': 15, 'grandparents': 87, 'grandma': 239, 'in-laws': 42, 'dads': 18, 'bffs': 1, 'love of my life': 39, 'younger brother': 46, 'stepmom': 2, 'eldest son': 12, 'brother-in-law': 28, 'great-grandmother': 4, 'grandmothers': 10, 'newborn': 54, 'ex-boyfriend': 5, 'stepdad': 6, 'grand-daughter': 5, 'buddy': 53, 'mommy': 55, 'strangers': 18, 'pals': 9, 'aunts': 21, 'bestie': 8, 'besties': 3, 'younger son': 18, 'everybody': 50, 'ex-husband': 9, 'adults': 14, 'folks': 17, 'elder son': 5, 'bae': 1, 'inlaws': 5, 'babe': 4, 'chicks': 18, 'bestfriend': 5, 'lads': 5, 'teenagers': 6, 'pappa': 1, 'grandaughter': 4, 'uncles': 11, 'daughter-in-law': 7, 'only child': 3, 'eldest child': 1, 'second son': 8, 'only son': 8, 'great-grandfather': 2, 'blonde': 4, 'babes': 1, 'grandmas': 6, 'stepfather': 2, 'infants': 1, 'momma': 8, 'fella': 4, 'fellas': 1, 'twin brother': 3, 'cutie': 2, 'mamma': 2, 'kiddos': 5, 'grannies': 1, 'great-granddaughter': 1, 'auntie': 2, 'preschoolers': 1, 'step-father': 1}\n"
     ]
    }
   ],
   "source": [
    "#[1]Use the lexicon to find the top three social relationships mentioned in happy moments\n",
    "# Initialize a dictionary to store the counts of social relationships\n",
    "relationship_counts = {}\n",
    "\n",
    "# Iterate through the \"cleaned happy moment\" column\n",
    "for moment in happyDB['cleaned_hm']:\n",
    "    # Convert the text to lowercase for case-insensitive matching\n",
    "    moment = moment.lower()\n",
    "    \n",
    "    # Check for the presence of social relationship terms in the lexicon\n",
    "    for relationship in relationship_lexicon['Relationship']:\n",
    "        if relationship in moment:\n",
    "            if relationship in relationship_counts:\n",
    "                relationship_counts[relationship] += 1\n",
    "            else:\n",
    "                relationship_counts[relationship] = 1\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8116627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friend: 13419\n",
      "men: 7038\n",
      "son: 6274\n"
     ]
    }
   ],
   "source": [
    "#Here we are finding the top 3 listed social relationships in the dataset. \n",
    "#For that we are using the sorted() function from the Python lists where we \n",
    "#sort in the decsending order\n",
    "\n",
    "# Sort the social relationships by count in descending order\n",
    "sorted_relationships = sorted(relationship_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Select the top three social relationships\n",
    "top_three_relationships = sorted_relationships[:3]\n",
    "\n",
    "# Print the top three social relationships and their counts\n",
    "for relationship, count in top_three_relationships:\n",
    "    print(f\"{relationship}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f41bdfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[2]Use your world knowledge to assess the strengths and weaknesses of the “people dictionary” in \n",
    "#terms of answering the question “with whom do people spend happy moments?” You can define \n",
    "#“people”, “strength” and “weakness” in your own way here. If you think this dictionary is already perfect, \n",
    "#you can articulate your argument and skip task #3 instead.\n",
    "\n",
    "#The strength of the dictionary is that it includes all kinds of social relationships\n",
    "#including the slang terms used for these relationships like \"bae\", \"bff\", \"kiddos\", \"grannies\"\n",
    "#However, according to me the weakness of the lexicon is that there are generic words also included such as\n",
    "#\"men\", \"guy\", \"someone\", \"people\", \"girl\". These words do not indicate any kind of social relationship in a society.\n",
    "#I believe that these words have to be removed from the lexicon to generate a revised lexicon. \n",
    "\n",
    "generic_words = [\"someone\",\"man\",\"girl\",\"people\",\"men\",\"everyone\",\"them\",\"women\",\"boy\",\"ladies\",\"lad\",\"ppl\",\"guy\",\"guys\",\n",
    "                 \"person\",\"woman\",\"lady\",\"boys\",\"girls\",\"somebody\",\"everybody\",\"adults\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a303693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friend: 13419\n",
      "son: 6274\n",
      "friends: 4527\n"
     ]
    }
   ],
   "source": [
    "#[3]Modify the “people dictionary” to fix the weaknesses that you have identified. \n",
    "#Use the revised lexicon to redo task #1.\n",
    "\n",
    "#Generic words from the list are deleted from the dictionary built in the previous step\n",
    "#This dictionary is specific to the particular dataset. \n",
    "\n",
    "for word in generic_words:\n",
    "    if word in relationship_counts:\n",
    "        del relationship_counts[word]\n",
    "\n",
    "\n",
    "# Sort the social relationships by count in descending order\n",
    "sorted_relationships = sorted(relationship_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Select the top three social relationships\n",
    "top_three_relationships = sorted_relationships[:3]\n",
    "\n",
    "# Print the top three social relationships and their counts\n",
    "for relationship, count in top_three_relationships:\n",
    "    print(f\"{relationship}: {count}\")\n",
    "    \n",
    "#Here we can see that the output shows that happy moments are usually seen when a person is spending time\n",
    "#with a friend, son or multiple number of friends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5514cb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friend\n",
      "son\n",
      "friends\n"
     ]
    }
   ],
   "source": [
    "for r in top_three_relationships:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5616a8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yashu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Word: old, Frequency: 721\n",
      "Context Word: best, Frequency: 692\n",
      "Context Word: friend., Frequency: 664\n",
      "Context Word: h, Frequency: 558\n",
      "Context Word: th, Frequency: 485\n",
      "Context Word: friend's, Frequency: 371\n",
      "Context Word: got, Frequency: 265\n",
      "Context Word: son's, Frequency: 245\n",
      "Context Word: son., Frequency: 230\n",
      "Context Word: g, Frequency: 225\n",
      "Context Word: n, Frequency: 225\n",
      "Context Word: good, Frequency: 208\n",
      "Context Word: ha, Frequency: 206\n",
      "Context Word: e, Frequency: 169\n",
      "Context Word: came, Frequency: 164\n",
      "Context Word: r, Frequency: 147\n",
      "Context Word: om, Frequency: 146\n",
      "Context Word: gave, Frequency: 140\n",
      "Context Word: lose, Frequency: 139\n",
      "Context Word: told, Frequency: 130\n",
      "Context Word: friend,, Frequency: 116\n",
      "Context Word: f, Frequency: 116\n",
      "Context Word: bi, Frequency: 111\n",
      "Context Word: hool, Frequency: 110\n",
      "Context Word: afte, Frequency: 106\n",
      "Context Word: new, Frequency: 101\n",
      "Context Word: son,, Frequency: 96\n",
      "Context Word: BEST, Frequency: 94\n",
      "Context Word: k, Frequency: 91\n",
      "Context Word: ed, Frequency: 90\n",
      "Context Word: call, Frequency: 87\n",
      "Context Word: BIRT, Frequency: 87\n",
      "Context Word: hood, Frequency: 86\n",
      "Context Word: w, Frequency: 84\n",
      "Context Word: made, Frequency: 83\n",
      "Context Word: ,, Frequency: 76\n",
      "Context Word: gest, Frequency: 76\n",
      "Context Word: dest, Frequency: 75\n",
      "Context Word: girl, Frequency: 74\n",
      "Context Word: play, Frequency: 69\n",
      "Context Word: ., Frequency: 67\n",
      "Context Word: BOY, Frequency: 65\n",
      "Context Word: star, Frequency: 61\n",
      "Context Word: MARR, Frequency: 61\n",
      "Context Word: ho, Frequency: 58\n",
      "Context Word: went, Frequency: 56\n",
      "Context Word: ther, Frequency: 55\n",
      "Context Word: LOVE, Frequency: 55\n",
      "Context Word: brou, Frequency: 52\n",
      "Context Word: Aft, Frequency: 52\n",
      "Context Word: sent, Frequency: 51\n",
      "Context Word: p, Frequency: 49\n",
      "Context Word: lear, Frequency: 49\n",
      "Context Word: ng, Frequency: 46\n",
      "Context Word: took, Frequency: 45\n",
      "Context Word: ba, Frequency: 45\n",
      "Context Word: invi, Frequency: 44\n",
      "Context Word: said, Frequency: 43\n",
      "Context Word: rece, Frequency: 41\n",
      "Context Word: boug, Frequency: 39\n",
      "Context Word: last, Frequency: 38\n",
      "Context Word: 9, Frequency: 38\n",
      "Context Word: ee, Frequency: 37\n",
      "Context Word: aske, Frequency: 37\n",
      "Context Word: abou, Frequency: 35\n",
      "Context Word: grad, Frequency: 35\n",
      "Context Word: toda, Frequency: 33\n",
      "Context Word: aw, Frequency: 33\n",
      "Context Word: met, Frequency: 33\n",
      "Context Word: marr, Frequency: 32\n",
      "Context Word: c, Frequency: 32\n",
      "Context Word: time, Frequency: 32\n",
      "Context Word: fina, Frequency: 32\n",
      "Context Word: help, Frequency: 32\n",
      "Context Word: dear, Frequency: 31\n",
      "Context Word: l, Frequency: 31\n",
      "Context Word: en, Frequency: 30\n",
      "Context Word: hit, Frequency: 30\n",
      "Context Word: text, Frequency: 28\n",
      "Context Word: lege, Frequency: 27\n",
      "Context Word: H, Frequency: 27\n",
      "Context Word: surp, Frequency: 26\n",
      "Context Word: nd, Frequency: 24\n",
      "Context Word: comp, Frequency: 24\n",
      "Context Word: pass, Frequency: 24\n",
      "Context Word: get, Frequency: 23\n",
      "Context Word: visi, Frequency: 23\n",
      "Context Word: birt, Frequency: 22\n",
      "Context Word: lp, Frequency: 22\n",
      "Context Word: et, Frequency: 21\n",
      "Context Word: ad, Frequency: 21\n",
      "Context Word: ne, Frequency: 20\n",
      "Context Word: move, Frequency: 20\n",
      "Context Word: lder, Frequency: 20\n",
      "Context Word: SCHO, Frequency: 20\n",
      "Context Word: sc, Frequency: 20\n",
      "Context Word: scor, Frequency: 20\n",
      "Context Word: yest, Frequency: 19\n",
      "Context Word: perf, Frequency: 19\n",
      "Context Word: -old, Frequency: 19\n"
     ]
    }
   ],
   "source": [
    "# Define the frequently mentioned social connections\n",
    "frequent_social_connections = [\"friend\", \"men\", \"son\"]\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Create a counter to store context words and their frequencies\n",
    "context_word_counter = Counter()\n",
    "\n",
    "# Get the NLTK stop words list\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Extract context words around each social connection\n",
    "for connection in frequent_social_connections:\n",
    "    # Iterate through each row of the dataset\n",
    "    for i, row in happyDB.iterrows():\n",
    "        text = row[\"cleaned_hm\"]\n",
    "        # Find instances of the social connection using regular expressions\n",
    "        instances = re.finditer(rf'\\b{re.escape(connection)}\\b', text, flags=re.IGNORECASE)\n",
    "        for instance in instances:\n",
    "            # Create a context window of five words before and after the instance\n",
    "            start_i = max(instance.start() - 5, 0)\n",
    "            end_i = min(instance.end() + 5, len(text))\n",
    "            context = text[start_i:end_i]\n",
    "            # Tokenize the context into words\n",
    "            words = context.split()\n",
    "            # Remove the social connection word and stop words from the context words\n",
    "            words = [word for word in words if word.lower() != connection.lower() and word.lower() not in stop_words]\n",
    "            # Update the context word counter\n",
    "            context_word_counter.update(words)\n",
    "\n",
    "# Sort context words by frequency in descending order\n",
    "sorted_context_words = context_word_counter.most_common()\n",
    "\n",
    "# Explore patterns in the 100 most frequent context words\n",
    "top_100_context_words = sorted_context_words[:100]\n",
    "\n",
    "# Print the list of 100 most frequent context words\n",
    "for word, frequency in top_100_context_words:\n",
    "    print(f\"Context Word: {word}, Frequency: {frequency}\")\n",
    "    \n",
    "\n",
    "#The output here indicates that \"old\",\"best\",\"friend\" are some of the context words \n",
    "#which occur when a person is happy. This indicates that whenever a person is having a \n",
    "#happy time with the best of his relationships then those are charectreized by these words\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
